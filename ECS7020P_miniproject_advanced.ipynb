{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ECS7020P Mini Project Advanced**\n",
        "**Student Name: Aakaash Balasubramanian**\n",
        "\n",
        "**Student ID: 230199668**"
      ],
      "metadata": {
        "id": "kHiH_EXEzMhX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Formulation**\n",
        "The machine learning problem addressed here is a multi-class classification task that focuses specifically on predicting the top 5 cuisines. The objective is to determine the cuisine type of a dish based on its ingredient list. The dataset contains images labeled with cuisine types and corresponding ingredient lists. Successfully solving this problem involves developing a model that excels at predicting the cuisine categories of dishes, with a particular emphasis on the top 5 cuisines. This refined approach aims to enhance the accuracy and interpretability of the model by concentrating on the most prevalent and discernible culinary traditions. The model's success would provide valuable insights into the cultural and culinary associations of the selected top cuisines."
      ],
      "metadata": {
        "id": "G0LKso6NzoPU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Machine Learning pipeline**\n",
        "**Input:** Raw dataset in a compressed format.\n",
        "\n",
        "**1.Data Download and Extraction:** Dataset is extracted to a readable format.\n",
        "\n",
        "**2.Data Preprocessing:** Processed dataset with handled missing values and transformed text data (ingredients) using CountVectorizer.\n",
        "\n",
        "**3.Modeling - Initial Attempt:** Built a Random Forest classifier to predict cuisine types. Split the dataset into training and testing sets. Evaluated the model's performance, which initially yielded low accuracy due to the multitude of cuisines.\n",
        "\n",
        "**4.Class Weighted Reduction:** Dropped cuisines with a limited number of data points to focus on the top 5 cuisines. Adjusted class weights to give less importance to Indian cuisine during model training.\n",
        "\n",
        "**5.Modeling - Final Attempt** Rebuilt the Random Forest classifier with the modified dataset. Split the dataset into training and testing sets. Evaluated the final model's performance, which demonstrated increased accuracy.\n",
        "\n",
        "**Output:** The type of cuisine based on ingredients."
      ],
      "metadata": {
        "id": "DQZk_c5C0mCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and extract the data. Install necessary libraries"
      ],
      "metadata": {
        "id": "NiUnoXq70-A_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Epkl28duqnI4",
        "outputId": "2eb9dba3-f630-4ef0-b762-c39872fc53b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlend\n",
            "  Downloading mlend-1.0.0.3-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: numpy>1.8 in /usr/local/lib/python3.10/dist-packages (from mlend) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mlend) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mlend) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mlend) (3.7.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from mlend) (1.3.2)\n",
            "Collecting spkit>0.0.9.5 (from mlend)\n",
            "  Downloading spkit-0.0.9.6.7-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from spkit>0.0.9.5->mlend) (1.2.2)\n",
            "Collecting python-picard (from spkit>0.0.9.5->mlend)\n",
            "  Downloading python_picard-0.7-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from spkit>0.0.9.5->mlend) (1.5.0)\n",
            "Collecting pylfsr (from spkit>0.0.9.5->mlend)\n",
            "  Downloading pylfsr-1.0.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from spkit>0.0.9.5->mlend) (3.9.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from spkit>0.0.9.5->mlend) (0.12.2)\n",
            "Collecting phyaat (from spkit>0.0.9.5->mlend)\n",
            "  Downloading phyaat-0.0.3-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mlend) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mlend) (1.16.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from python-picard->spkit>0.0.9.5->mlend) (2.8.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->spkit>0.0.9.5->mlend) (3.2.0)\n",
            "Installing collected packages: python-picard, pylfsr, phyaat, spkit, mlend\n",
            "Successfully installed mlend-1.0.0.3 phyaat-0.0.3 pylfsr-1.0.7 python-picard-0.7 spkit-0.0.9.6.7\n"
          ]
        }
      ],
      "source": [
        "pip install mlend --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlend\n",
        "from mlend import download_yummy, yummy_load\n",
        "\n",
        "subset = {}\n",
        "\n",
        "datadir = download_yummy(save_to = '/content/drive/MyDrive/Data/MLEnd', subset = subset,verbose=1,overwrite=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWZBuRw_rPuv",
        "outputId": "faa76de3-9b2a-43bd-ee89-d052360c59fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 3250 image files from https://github.com/MLEndDatasets/Yummy\n",
            "100%|\u001b[0m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[0m|3250\\3250|003250.jpg\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib"
      ],
      "metadata": {
        "id": "x5GvSKgurTd3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset**\n",
        "\n",
        "The MLEND Yummy Dataset is a comprehensive collection of culinary information, featuring various attributes related to dishes, cuisine types, and visual representations through images. The dataset is structured as a DataFrame with 3250 rows and 12 columns, each corresponding to different aspects of the culinary data."
      ],
      "metadata": {
        "id": "1TXwORkt-NwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "dataset_path = '/content/drive/MyDrive/Data/MLEnd/yummy/MLEndYD_image_attributes_benchmark.csv'\n",
        "df = pd.read_csv(dataset_path)"
      ],
      "metadata": {
        "id": "L9rZ86Iy0BdG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "CqevgzjA0WSK",
        "outputId": "2d028489-e0c8-4fa6-d307-0664dd792430"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        filename            Diet Cuisine_org   Cuisine  \\\n",
              "0     000001.jpg  non_vegetarian    japanese  japanese   \n",
              "1     000002.jpg  non_vegetarian     english   english   \n",
              "2     000003.jpg  non_vegetarian     chinese   chinese   \n",
              "3     000004.jpg      vegetarian      indian    indian   \n",
              "4     000005.jpg  non_vegetarian      indian    indian   \n",
              "...          ...             ...         ...       ...   \n",
              "3245  003246.jpg      vegetarian      indian    indian   \n",
              "3246  003247.jpg      vegetarian      indian    indian   \n",
              "3247  003248.jpg      vegetarian      indian    indian   \n",
              "3248  003249.jpg           vegan      indian    indian   \n",
              "3249  003250.jpg  non_vegetarian    american  american   \n",
              "\n",
              "                             Dish_name     Home_or_restaurant  \\\n",
              "0                   chicken_katsu_rice          marugame_udon   \n",
              "1                    english_breakfast                   home   \n",
              "2                        spicy_chicken  jinli_flagship_branch   \n",
              "3                          gulab_jamun                   home   \n",
              "4                       chicken_masala                   home   \n",
              "...                                ...                    ...   \n",
              "3245                        zeera_rice                   home   \n",
              "3246                    paneer_and_dal                   home   \n",
              "3247                            samosa                   home   \n",
              "3248                        fruit_milk                   home   \n",
              "3249  beef_burger_with_onion_and_salad                   home   \n",
              "\n",
              "                                            Ingredients Healthiness_rating  \\\n",
              "0                 rice,chicken_breast,spicy_curry_sauce            neutral   \n",
              "1     eggs,bacon,hash_brown,tomato,bread,tomato,bake...          unhealthy   \n",
              "2     chili,chicken,peanuts,sihuan_peppercorns,green...            neutral   \n",
              "3         sugar,water,khoya,milk,salt,oil,cardamon,ghee          unhealthy   \n",
              "4     chicken,lemon,turmeric,garam_masala,coriander_...            healthy   \n",
              "...                                                 ...                ...   \n",
              "3245  1_cup_basmati_rice,2_cups_water,2_tablespoons_...            healthy   \n",
              "3246  fried_cottage_cheese,ghee,lentils,milk,wheat_f...            healthy   \n",
              "3247  potato,onion,peanut,salt,turmeric_powder,red_c...     very_unhealthy   \n",
              "3248                             kiwi,banana,apple,milk       very_healthy   \n",
              "3249   beef_patty,bread_roll,cherry_tomato,_onion,chive            neutral   \n",
              "\n",
              "      Healthiness_rating_int       Likeness  Likeness_int Benchmark_A  \n",
              "0                        3.0           like           4.0       Train  \n",
              "1                        2.0           like           4.0       Train  \n",
              "2                        3.0  strongly_like           5.0       Train  \n",
              "3                        2.0  strongly_like           5.0       Train  \n",
              "4                        4.0  strongly_like           5.0       Train  \n",
              "...                      ...            ...           ...         ...  \n",
              "3245                     4.0  strongly_like           5.0       Train  \n",
              "3246                     4.0  strongly_like           5.0        Test  \n",
              "3247                     1.0           like           4.0        Test  \n",
              "3248                     5.0  strongly_like           5.0       Train  \n",
              "3249                     3.0           like           4.0       Train  \n",
              "\n",
              "[3250 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02ba77da-1326-4bb1-8898-0d86a85513f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>Diet</th>\n",
              "      <th>Cuisine_org</th>\n",
              "      <th>Cuisine</th>\n",
              "      <th>Dish_name</th>\n",
              "      <th>Home_or_restaurant</th>\n",
              "      <th>Ingredients</th>\n",
              "      <th>Healthiness_rating</th>\n",
              "      <th>Healthiness_rating_int</th>\n",
              "      <th>Likeness</th>\n",
              "      <th>Likeness_int</th>\n",
              "      <th>Benchmark_A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000001.jpg</td>\n",
              "      <td>non_vegetarian</td>\n",
              "      <td>japanese</td>\n",
              "      <td>japanese</td>\n",
              "      <td>chicken_katsu_rice</td>\n",
              "      <td>marugame_udon</td>\n",
              "      <td>rice,chicken_breast,spicy_curry_sauce</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3.0</td>\n",
              "      <td>like</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>non_vegetarian</td>\n",
              "      <td>english</td>\n",
              "      <td>english</td>\n",
              "      <td>english_breakfast</td>\n",
              "      <td>home</td>\n",
              "      <td>eggs,bacon,hash_brown,tomato,bread,tomato,bake...</td>\n",
              "      <td>unhealthy</td>\n",
              "      <td>2.0</td>\n",
              "      <td>like</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000003.jpg</td>\n",
              "      <td>non_vegetarian</td>\n",
              "      <td>chinese</td>\n",
              "      <td>chinese</td>\n",
              "      <td>spicy_chicken</td>\n",
              "      <td>jinli_flagship_branch</td>\n",
              "      <td>chili,chicken,peanuts,sihuan_peppercorns,green...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000004.jpg</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>gulab_jamun</td>\n",
              "      <td>home</td>\n",
              "      <td>sugar,water,khoya,milk,salt,oil,cardamon,ghee</td>\n",
              "      <td>unhealthy</td>\n",
              "      <td>2.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000005.jpg</td>\n",
              "      <td>non_vegetarian</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>chicken_masala</td>\n",
              "      <td>home</td>\n",
              "      <td>chicken,lemon,turmeric,garam_masala,coriander_...</td>\n",
              "      <td>healthy</td>\n",
              "      <td>4.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3245</th>\n",
              "      <td>003246.jpg</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>zeera_rice</td>\n",
              "      <td>home</td>\n",
              "      <td>1_cup_basmati_rice,2_cups_water,2_tablespoons_...</td>\n",
              "      <td>healthy</td>\n",
              "      <td>4.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3246</th>\n",
              "      <td>003247.jpg</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>paneer_and_dal</td>\n",
              "      <td>home</td>\n",
              "      <td>fried_cottage_cheese,ghee,lentils,milk,wheat_f...</td>\n",
              "      <td>healthy</td>\n",
              "      <td>4.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3247</th>\n",
              "      <td>003248.jpg</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>samosa</td>\n",
              "      <td>home</td>\n",
              "      <td>potato,onion,peanut,salt,turmeric_powder,red_c...</td>\n",
              "      <td>very_unhealthy</td>\n",
              "      <td>1.0</td>\n",
              "      <td>like</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3248</th>\n",
              "      <td>003249.jpg</td>\n",
              "      <td>vegan</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>fruit_milk</td>\n",
              "      <td>home</td>\n",
              "      <td>kiwi,banana,apple,milk</td>\n",
              "      <td>very_healthy</td>\n",
              "      <td>5.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3249</th>\n",
              "      <td>003250.jpg</td>\n",
              "      <td>non_vegetarian</td>\n",
              "      <td>american</td>\n",
              "      <td>american</td>\n",
              "      <td>beef_burger_with_onion_and_salad</td>\n",
              "      <td>home</td>\n",
              "      <td>beef_patty,bread_roll,cherry_tomato,_onion,chive</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3.0</td>\n",
              "      <td>like</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3250 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02ba77da-1326-4bb1-8898-0d86a85513f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-02ba77da-1326-4bb1-8898-0d86a85513f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-02ba77da-1326-4bb1-8898-0d86a85513f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-878e8593-3d05-4099-93a6-50e1f615363a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-878e8593-3d05-4099-93a6-50e1f615363a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-878e8593-3d05-4099-93a6-50e1f615363a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the data for a machine learning model by handling missing values, checking for NaN values, and transforming the text data (ingredients) into a numerical format using the CountVectorizer."
      ],
      "metadata": {
        "id": "MlsPlWAV1Zra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transformation stage**\n",
        "Several transformations were applied to the dataset to refine it for model training. First, any missing values in the dataset were removed to ensure data completeness. Additionally, the textual data representing ingredients was transformed into a numerical format using vectorization, specifically the CountVectorizer. This conversion enables the machine learning model to interpret and learn from the ingredient data, facilitating the classification of cuisines based on their characteristic ingredients. The chosen transformations aim to optimize the dataset for effective model training, emphasizing relevant cuisines and representing textual data in a numerical format that aligns with the requirements of the machine learning algorithm."
      ],
      "metadata": {
        "id": "bfTmMREAAvSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Ingredients'] = df['Ingredients'].fillna('')  # Fill NaN values with an empty string\n",
        "df['Cuisine_org'] = df['Cuisine_org'].fillna('')  # Fill NaN values with an empty string\n",
        "\n",
        "# Check for NaN values in the DataFrame\n",
        "print(\"NaN values in 'Ingredients':\", df['Ingredients'].isnull().sum())\n",
        "print(\"NaN values in 'Cuisine_org':\", df['Cuisine_org'].isnull().sum())\n",
        "\n",
        "# Feature Engineering\n",
        "X = df['Ingredients']\n",
        "y = df['Cuisine_org']\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_transformed = vectorizer.fit_transform(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw5LgImU0e83",
        "outputId": "a260308b-b464-4c17-f90d-5435a1ae03af"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN values in 'Ingredients': 0\n",
            "NaN values in 'Cuisine_org': 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelling**\n",
        "The chosen machine learning model for this task is the Random Forest Classifier. This decision is grounded in the algorithm's robust performance in handling multi-class classification problems, particularly when dealing with a diverse set of cuisines derived from ingredient data. Random Forests excel in capturing intricate patterns within datasets, offering a high degree of accuracy and resilience to overfitting. Additionally, their ensemble nature, combining multiple decision trees, makes them adept at handling complex relationships between ingredients and cuisine types. The inherent ability to assess feature importance aids in interpreting the significance of different ingredients in predicting cuisine, contributing to a more interpretable and insightful model. Overall, the Random Forest Classifier was selected for its versatility, effectiveness in multi-class classification, and suitability for capturing intricate patterns in the ingredient-based dataset."
      ],
      "metadata": {
        "id": "vb4t3GKaBm06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Methodology**\n",
        "The training and validation of the models involve a systematic process to ensure robust performance and accurate predictions. The dataset is split into training and testing sets using a train-test split.The Random Forest Classifier is then trained on the training set, learning the relationships between ingredients and cuisine types. Model performance is assessed using a variety of metrics, including accuracy, which measures the overall correctness of predictions. The confusion matrix provides a detailed breakdown of true positive, true negative, false positive, and false negative predictions, offering insights into specific classification errors. Precision, recall, and F1 score complement accuracy by quantifying the model's precision in positive predictions, its ability to capture all relevant instances, and the balance between precision and recall, respectively. These metrics collectively offer a comprehensive evaluation of the model's predictive capabilities, enabling a nuanced understanding of its strengths and potential areas for improvement."
      ],
      "metadata": {
        "id": "Wi-gQbrBCXms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building, training, evaluating, and saving a machine learning model."
      ],
      "metadata": {
        "id": "ILcw0A2f1ova"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model Selection and Training\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Display classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Save the trained model for future use\n",
        "model_filename = '/content/drive/MyDrive/Data/MLEnd/recipe_classifier_model.pkl'\n",
        "joblib.dump(model, model_filename)\n",
        "print(f'Model saved to {model_filename}')\n",
        "\n",
        "# Inference (Predicting cuisine type for new dishes)\n",
        "# Assuming 'new_dishes' is a list of dishes with their ingredients\n",
        "new_dishes = [\n",
        "    \"pasta, tomato sauce, cheese\",\n",
        "    \"sushi rice, nori, salmon, avocado\",\n",
        "    \"chicken, curry powder, coconut milk, potatoes\"\n",
        "]\n",
        "\n",
        "# Transform the new dishes using the same vectorizer\n",
        "new_dishes_transformed = vectorizer.transform(new_dishes)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(new_dishes_transformed)\n",
        "\n",
        "# Display the predictions\n",
        "for dish, prediction in zip(new_dishes, predictions):\n",
        "    print(f'Dish: {dish}, Predicted Cuisine: {prediction}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPONdAbO0rAc",
        "outputId": "5c565cc1-dbcc-4697-ab85-e3814a46dbdb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.53\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "                            1.00      1.00      1.00         1\n",
            "              afghani       0.00      0.00      0.00         2\n",
            "              african       0.00      0.00      0.00         1\n",
            "              america       0.50      0.50      0.50         2\n",
            "             american       0.49      0.52      0.50        58\n",
            "     american_cuisine       0.00      0.00      0.00         2\n",
            "                 arab       1.00      0.50      0.67         2\n",
            "                asian       0.00      0.00      0.00         3\n",
            "           australian       0.00      0.00      0.00         1\n",
            "                azeri       0.50      1.00      0.67         1\n",
            "          bangladeshi       0.00      0.00      0.00         2\n",
            "              belgian       0.00      0.00      0.00         1\n",
            "              british       0.24      0.21      0.22        38\n",
            "            bulgarian       0.00      0.00      0.00         2\n",
            "                china       0.00      0.00      0.00         1\n",
            "              chinese       0.42      0.68      0.52        69\n",
            "            columbian       0.00      0.00      0.00         1\n",
            "          continental       0.00      0.00      0.00         4\n",
            "               danish       1.00      1.00      1.00         1\n",
            "eastern_mediterranean       0.00      0.00      0.00         2\n",
            "             egyptian       0.00      0.00      0.00         2\n",
            "              england       0.00      0.00      0.00         1\n",
            "              english       0.55      0.43      0.48        14\n",
            "               europe       0.00      0.00      0.00         1\n",
            "             european       0.00      0.00      0.00         5\n",
            "            fast_food       0.00      0.00      0.00         4\n",
            "               french       0.67      0.40      0.50        10\n",
            "                fruit       0.00      0.00      0.00         1\n",
            "               fusion       0.00      0.00      0.00         1\n",
            "              general       0.00      0.00      0.00         3\n",
            "               german       0.00      0.00      0.00         1\n",
            "              germany       0.00      0.00      0.00         1\n",
            "               global       1.00      0.50      0.67         2\n",
            "               greece       0.00      0.00      0.00         1\n",
            "                greek       0.00      0.00      0.00         1\n",
            "               indain       0.00      0.00      0.00         1\n",
            "               indian       0.61      0.92      0.73       209\n",
            "        indo-_chinese       0.00      0.00      0.00         1\n",
            "         indo-chinese       0.00      0.00      0.00         5\n",
            "           indonesian       0.00      0.00      0.00         5\n",
            "        international       0.00      0.00      0.00         1\n",
            "              iranian       0.00      0.00      0.00         1\n",
            "              italian       0.59      0.72      0.65        53\n",
            "             jamaican       0.00      0.00      0.00         1\n",
            "             japanese       1.00      0.21      0.35        14\n",
            "               jordan       0.00      0.00      0.00         1\n",
            "               kerala       0.00      0.00      0.00         1\n",
            "               korean       0.00      0.00      0.00         5\n",
            " lebanese/palestinian       0.00      0.00      0.00         1\n",
            "        mediterranean       0.00      0.00      0.00         4\n",
            "              mexican       0.67      0.29      0.40         7\n",
            "mexican/international       0.00      0.00      0.00         1\n",
            "       middle_eastern       0.50      0.20      0.29         5\n",
            "               modern       0.00      0.00      0.00         1\n",
            "             nigerian       0.00      0.00      0.00         0\n",
            "               nordic       0.00      0.00      0.00         1\n",
            "         north_indian       1.00      0.17      0.29         6\n",
            "            norwegian       0.00      0.00      0.00         1\n",
            "            pakistani       0.50      0.17      0.25        12\n",
            "              persian       0.00      0.00      0.00         2\n",
            "             peruvian       0.00      0.00      0.00         1\n",
            "               poland       0.00      0.00      0.00         1\n",
            "           portuguese       0.00      0.00      0.00         9\n",
            "              russian       0.00      0.00      0.00         1\n",
            "             scottish       0.00      0.00      0.00         4\n",
            "                snack       0.00      0.00      0.00         2\n",
            "        south_african       0.00      0.00      0.00         1\n",
            "          south_asian       1.00      0.50      0.67         2\n",
            "         south_indian       0.00      0.00      0.00        13\n",
            "              spanish       0.00      0.00      0.00         1\n",
            "           sri_lankan       0.00      0.00      0.00         1\n",
            "            srilankan       0.00      0.00      0.00         1\n",
            "                sudan       0.00      0.00      0.00         2\n",
            "            taiwanese       0.00      0.00      0.00         2\n",
            "                 thai       0.00      0.00      0.00         4\n",
            "             thailand       0.00      0.00      0.00         0\n",
            "          traditional       0.00      0.00      0.00         1\n",
            "              turkish       1.00      0.09      0.17        11\n",
            "                udupi       0.00      0.00      0.00         1\n",
            "                   uk       0.00      0.00      0.00         3\n",
            "                  usa       0.00      0.00      0.00         2\n",
            "                uzbek       0.00      0.00      0.00         1\n",
            "           vietnamese       1.00      0.33      0.50         3\n",
            "              western       0.00      0.00      0.00         2\n",
            "\n",
            "             accuracy                           0.53       650\n",
            "            macro avg       0.18      0.12      0.13       650\n",
            "         weighted avg       0.45      0.53      0.46       650\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/Data/MLEnd/recipe_classifier_model.pkl\n",
            "Dish: pasta, tomato sauce, cheese, Predicted Cuisine: italian\n",
            "Dish: sushi rice, nori, salmon, avocado, Predicted Cuisine: japanese\n",
            "Dish: chicken, curry powder, coconut milk, potatoes, Predicted Cuisine: indian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The low accuracy observed in the model evaluation results is primarily due to the presence of a large number of diverse cuisines in the dataset. The model is struggling to accurately predict less prevalent cuisines, resulting in a low overall accuracy."
      ],
      "metadata": {
        "id": "y2u6SKiK4lr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To focus the analysis, the dataset has been refined to include only the top 5 cuisines. The updated distribution shows the count of recipes for each of the cuisines. This reduction in the number of cuisines is intended to simplify the classification task, potentially improving the model's ability to predict cuisine types accurately, especially for the more prevalent categories. The refined dataset with the top 5 cuisines will be used for further analysis and model training."
      ],
      "metadata": {
        "id": "8hqeu4UO4Grs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the distribution of cuisines\n",
        "cuisine_distribution = df['Cuisine_org'].value_counts()\n",
        "print(\"Cuisine Distribution:\")\n",
        "print(cuisine_distribution)\n",
        "\n",
        "# Select the top 4 or 5 cuisines\n",
        "top_cuisines = cuisine_distribution.head(5).index.tolist()\n",
        "\n",
        "# Filter the dataset for the selected cuisines\n",
        "df_filtered = df[df['Cuisine_org'].isin(top_cuisines)]\n",
        "\n",
        "# Print the updated distribution\n",
        "print(\"\\nTop Cuisines:\")\n",
        "print(df_filtered['Cuisine_org'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqeHF2q60wmr",
        "outputId": "4f008b92-4c9d-4e6e-8914-db73fde97226"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuisine Distribution:\n",
            "indian            1102\n",
            "chinese            332\n",
            "italian            279\n",
            "american           239\n",
            "british            193\n",
            "                  ... \n",
            "argentina            1\n",
            "middle-east          1\n",
            "united_states        1\n",
            "tropical             1\n",
            "german/turkish       1\n",
            "Name: Cuisine_org, Length: 182, dtype: int64\n",
            "\n",
            "Top Cuisines:\n",
            "indian      1102\n",
            "chinese      332\n",
            "italian      279\n",
            "american     239\n",
            "british      193\n",
            "Name: Cuisine_org, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the dataset for the top 5 cuisines\n",
        "top_cuisines = ['indian', 'chinese', 'italian', 'american', 'british']\n",
        "df_filtered = df[df['Cuisine_org'].isin(top_cuisines)]\n",
        "\n",
        "# Print the updated distribution\n",
        "print(\"\\nTop Cuisines:\")\n",
        "print(df_filtered['Cuisine_org'].value_counts())\n",
        "\n",
        "# Feature Engineering on the filtered dataset\n",
        "X_filtered = df_filtered['Ingredients']\n",
        "y_filtered = df_filtered['Cuisine_org']\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_transformed_filtered = vectorizer.fit_transform(X_filtered)\n",
        "\n",
        "# Split the filtered dataset\n",
        "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
        "    X_transformed_filtered, y_filtered, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Model Selection and Training on the filtered dataset\n",
        "model_filtered = RandomForestClassifier()\n",
        "model_filtered.fit(X_train_filtered, y_train_filtered)\n",
        "\n",
        "# Model Evaluation on the filtered dataset\n",
        "y_pred_filtered = model_filtered.predict(X_test_filtered)\n",
        "accuracy_filtered = accuracy_score(y_test_filtered, y_pred_filtered)\n",
        "\n",
        "print(f'Accuracy on Filtered Dataset: {accuracy_filtered:.2f}')\n",
        "\n",
        "# Display classification report on the filtered dataset\n",
        "print(classification_report(y_test_filtered, y_pred_filtered))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sQrN9zn28re",
        "outputId": "8b8c84b6-581b-40e6-a723-bc7066e8adbf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top Cuisines:\n",
            "indian      1102\n",
            "chinese      332\n",
            "italian      279\n",
            "american     239\n",
            "british      193\n",
            "Name: Cuisine_org, dtype: int64\n",
            "Accuracy on Filtered Dataset: 0.74\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    american       0.81      0.51      0.62        57\n",
            "     british       0.44      0.33      0.38        36\n",
            "     chinese       0.55      0.71      0.62        70\n",
            "      indian       0.83      0.89      0.86       211\n",
            "     italian       0.82      0.73      0.77        55\n",
            "\n",
            "    accuracy                           0.74       429\n",
            "   macro avg       0.69      0.63      0.65       429\n",
            "weighted avg       0.75      0.74      0.74       429\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering the dataset to focus on the top 5 cuisines—American, British, Chinese, Indian, and Italian—has led to a significant improvement in model performance. The model demonstrates high precision, recall, and F1-scores for these specific cuisine categories, leading to an overall improved accuracy of 74%. This narrowing down of classes has effectively addressed the challenges associated with a large number of diverse cuisines, resulting in a more effective and interpretable model for predicting cuisine types based on ingredients."
      ],
      "metadata": {
        "id": "bBU7AA9Y5le2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Define parameter grid for RandomForestClassifier\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Instantiate RandomForestClassifier\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# Use GridSearchCV for hyperparameter tuning\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train_filtered, y_train_filtered)\n",
        "\n",
        "# Get the best parameters and retrain the model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = RandomForestClassifier(**best_params)\n",
        "best_model.fit(X_train_filtered, y_train_filtered)\n",
        "\n",
        "# Model Evaluation on the filtered dataset with the best model\n",
        "y_pred_filtered_best = best_model.predict(X_test_filtered)\n",
        "accuracy_filtered_best = accuracy_score(y_test_filtered, y_pred_filtered_best)\n",
        "\n",
        "print(f'Best Model Accuracy on Filtered Dataset: {accuracy_filtered_best:.2f}')\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "\n",
        "# Display precision, recall, and F1-score for each class\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test_filtered, y_pred_filtered_best, average=None)\n",
        "\n",
        "class_names = best_model.classes_\n",
        "for i, class_name in enumerate(class_names):\n",
        "    print(f\"\\nClass: {class_name}\")\n",
        "    print(f\"Precision: {precision[i]:.2f}\")\n",
        "    print(f\"Recall: {recall[i]:.2f}\")\n",
        "    print(f\"F1-Score: {f1_score[i]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK4Sb0Hk3HGJ",
        "outputId": "a052a7b8-21c4-48d3-ea16-d99ab7c581e3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model Accuracy on Filtered Dataset: 0.75\n",
            "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "\n",
            "Class: american\n",
            "Precision: 0.81\n",
            "Recall: 0.51\n",
            "F1-Score: 0.62\n",
            "\n",
            "Class: british\n",
            "Precision: 0.50\n",
            "Recall: 0.28\n",
            "F1-Score: 0.36\n",
            "\n",
            "Class: chinese\n",
            "Precision: 0.58\n",
            "Recall: 0.69\n",
            "F1-Score: 0.63\n",
            "\n",
            "Class: indian\n",
            "Precision: 0.81\n",
            "Recall: 0.91\n",
            "F1-Score: 0.86\n",
            "\n",
            "Class: italian\n",
            "Precision: 0.79\n",
            "Recall: 0.75\n",
            "F1-Score: 0.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The improvement in accuracy after tuning the hyperparameters can be attributed to the optimization of the model's internal settings. By finding the best hyperparameter configuration the model is fine tuned to better capture patterns in the data and improve its ability to generalize to unseen examples."
      ],
      "metadata": {
        "id": "CnIL2-eY6t1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of Indian cuisines is significantly larger than number of other cuisines. So the model specifically performs well on the Indian cuisine."
      ],
      "metadata": {
        "id": "um8RxwsT9C3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Results:**\n",
        "The experiments involved two key steps to enhance model performance. First, by restricting the dataset to the top 5 cuisines, the model's accuracy showed a notable increase. This reduction in the number of classes allowed the model to focus on the most prevalent cuisines, enhancing its ability to discern patterns and relationships within the dataset. Subsequently, adjusting the class weights, specifically reducing the weight assigned to Indian cuisine, led to a further increase in accuracy. This adjustment was crucial due to the large number of Indian dishes in the dataset, ensuring a more balanced influence of different cuisines during model training. The improved accuracy post these experiments signifies that the model benefited from a more focused set of cuisines and a nuanced handling of class weights, underscoring the importance of strategic preprocessing steps in refining the model's predictive capabilities."
      ],
      "metadata": {
        "id": "hfEgEkKsCqWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class weights, giving a lower weight to the 'indian' class\n",
        "class_weights = {'american': 1, 'british': 1, 'chinese': 1, 'indian': 0.2, 'italian': 1}\n",
        "\n",
        "# Instantiate RandomForestClassifier with class weights\n",
        "model_weighted = RandomForestClassifier(class_weight=class_weights, **best_params)\n",
        "\n",
        "# Train the model on the filtered dataset with class weights\n",
        "model_weighted.fit(X_train_filtered, y_train_filtered)\n",
        "\n",
        "# Model Evaluation on the filtered dataset with the weighted model\n",
        "y_pred_weighted = model_weighted.predict(X_test_filtered)\n",
        "accuracy_weighted = accuracy_score(y_test_filtered, y_pred_weighted)\n",
        "\n",
        "print(f'Weighted Model Accuracy on Filtered Dataset: {accuracy_weighted:.2f}')\n",
        "\n",
        "# Display classification report on the filtered dataset with class weights\n",
        "print(classification_report(y_test_filtered, y_pred_weighted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkYLuabx4p8s",
        "outputId": "36e110f0-d2b3-4e83-d065-977fec5ab603"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted Model Accuracy on Filtered Dataset: 0.78\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    american       0.77      0.58      0.66        57\n",
            "     british       0.59      0.36      0.45        36\n",
            "     chinese       0.58      0.83      0.68        70\n",
            "      indian       0.89      0.89      0.89       211\n",
            "     italian       0.80      0.80      0.80        55\n",
            "\n",
            "    accuracy                           0.78       429\n",
            "   macro avg       0.73      0.69      0.70       429\n",
            "weighted avg       0.79      0.78      0.78       429\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By adjusting the class weights, specifically assigning a lower weight (0.2) to the Indian cuisine class while maintaining equal weights (1) for other top cuisines the model's accuracy experienced a notable improvement. This modification was implemented to address the imbalance in the dataset, as Indian cuisines were more prevalent than others. By assigning a lower weight to the Indian cuisine class, the model became more attuned to the distinctive features of this category, resulting in enhanced accuracy. This approach effectively prioritized the correct classification of Indian cuisines while ensuring a balanced consideration of the other selected cuisines. The refined class weights contributed to a more nuanced and accurate prediction of cuisine types, especially in scenarios with imbalanced class distributions."
      ],
      "metadata": {
        "id": "Ktn9vzUs8_dW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**\n",
        "\n",
        "The experiments conducted on the machine learning model, specifically the reduction of cuisines to the top 5 and the adjustment of class weights for Indian dishes, yielded substantial improvements in accuracy. The decision to focus on the most prevalent cuisines allowed the model to specialize in recognizing patterns within a more concentrated set of classes, resulting in an initial boost in accuracy. Additionally, reducing the class weight for Indian dishes was instrumental in addressing the imbalance created by the large number of Indian cuisine samples. This adjustment further contributed to accuracy gains by mitigating the undue influence of Indian dishes during training. For future improvements, exploring more sophisticated techniques for handling imbalanced datasets and experimenting with hyperparameter tuning could enhance model performance. Additionally, ongoing evaluation and potential refinement of class weights based on the evolving dataset may contribute to sustained accuracy improvements. Overall, these findings underscore the importance of thoughtful preprocessing steps in tailoring the model to the characteristics of the dataset, leading to more accurate and robust predictions."
      ],
      "metadata": {
        "id": "fxyW5XHUDNqT"
      }
    }
  ]
}